---
title: "Analysis of Phenotypic Data from Human Pancreatic Islets"
author: "Nikolay Oskolkov, SciLifeLab, NBIS Long Term Support, nikolay.oskolkov@scilifelab.se"
date: "January 17, 2020"
output:
  html_document:
    toc: yes
  pdf_document:
    toc: yes
subtitle: PI Charlotte Ling, Lund University
abstract: |
  Here we will use the available phenotypic data from Human Pancreatic Islets from individuals with and without Type 2 Diabetes (T2D) and perform diebetes status linear predictive analysis with PLS-DA model on 110 manually selected individuals with most reliable phenotypic information.
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir="/home/nikolay/WABI/C_Ling/Analysis_110ind_Selected/")
```


### The List of 110 Selected Individuals

All the analysis will be performed on the 110 individuals which were selected based on multiple criteria such as 1) they are either normo-glycimic or hyper-glycemic / T2D individuals, 2) they have information from all the 4 OMICS (methylation, transcriptomics, phenotypes, genotypes), 3) they all fall within the same age category, and a few other minor criteria. Now we will read the list of those 110 individuals and display a few of them:

```{r}
set.seed(1)
selected_ind<-scan("OVERLAPPING_110_SAMPLES_4OMICS.txt", what = "charater")
selected_ind<-paste0("ID",selected_ind)
print(head(selected_ind, 20))
print(tail(selected_ind, 20))
```


### Checking Human Islets Phenotypes

We will start with the analysis of phenotypes available from approximately 300 Human Panctreatic Islets in order to check the relation between the phenotypes. Later this information will be taken into account when we do batch-effects correction. 
The phenotype file below was provided by Human Tissue Lab (HTL) from Lund University Diabetes Center (LUDC), it includes phenotypic information from approximately 300 pancreatic islets donors. Not all of them will overlap with the methylation array, RNAseq and genotyping array samples but we still will use the info from all available donors in order to establish how phenotypes are correlated with each other. We start with reading the file and removing non-relevant phenotypes: 

* HTL_donor_ID: Human Tissue Lab Donor ID)
* NICS_donor_ID: Uppsala donor ID
* Birth: redundant, captured by Age variable
* HbA1c_mmol_mol: redundant, captured by HbA1c_perc
* Blood_group: unlikely to be related to Type 2 Diabetes
* Non_diabetic: redundant, captured by T2D variable
* GAD: not related to T2D
* Gestational: appropriate only for females, will be correlated with Sex
* Date_isolated_islets: unlikely to be related to Type 2 Diabetes
* Date_recieved_islets: unlikely to be related to Type 2 Diabetes
* Islet_equivalences: unlikely to be related to Type 2 Diabetes
* Diabetes_treatment: too sparse information

We will also add information about Methylation EPIC Array batches and RNAseq batches (old vs. new chemistry) in order to see what phenotypes the batches correlate with. This is a potential danger if the batches happen to correlate with valuables phenotypes like T2D or HbA1c. As a control of noise level we will introduce a random variable, we will use it to check later how much of phenotypic variation can be explained by chance.

```{r read phenotypes}
htl<-read.csv("htl_donors.csv",header=TRUE,check.names=FALSE)
htl$HTL_donor_ID<-paste0("ID",htl$HTL_donor_ID)
phen_meth_batch<-read.delim("phenotypes_islets.txt",header=TRUE,row.names=1,check.names=FALSE,sep="\t")
htl$Meth_Batch<-phen_meth_batch$batch[match(as.character(htl$HTL_donor_ID),rownames(phen_meth_batch))]
htl$Meth_Batch[is.na(htl$Meth_Batch)]<-21
phen_rnaseq_batch<-read.delim("phen_rnaseq_batch.txt",header=TRUE,row.names=1,check.names=FALSE,sep="\t")
htl$RNA_Batch<-phen_rnaseq_batch$batch[match(as.character(htl$HTL_donor_ID),rownames(phen_rnaseq_batch))]
htl$Random<-log(sample(dim(htl)[1]))
rownames(htl)<-htl$HTL_donor_ID

htl$HTL_donor_ID<-NULL
htl$NICS_donor_ID<-NULL
htl$Birth<-NULL
htl$HbA1c_mmol_mol<-NULL
htl$Blood_group<-NULL
htl$Non_diabetic<-NULL
htl$GAD<-NULL
htl$Gestational<-NULL
htl$Date_isolated_islets<-NULL
htl$Date_recieved_islets<-NULL
htl$Islet_equivalences<-NULL
htl$Diabetes_treatment<-NULL
head(htl)
```

For convenience we will rename HbA1c_perc to HbA1c, Stimulatory_index to SI, Purity_perc to Purity, Days_cultured to DIC. We will also assign donors with HbA1c > 6.5 to diabetics and balance the data set a bit better in this way. 

```{r rename columns}
names(htl)[names(htl)=="HbA1c_perc"]<-"HbA1c"
names(htl)[names(htl)=="Stimulatory_index"]<-"SI"
names(htl)[names(htl)=="Purity_perc"]<-"Purity"
names(htl)[names(htl)=="Days_cultured"]<-"DIC"
htl$T2D<-ifelse( ((is.na(htl$T2D)==FALSE & htl$T2D==1) | (is.na(htl$HbA1c)==FALSE  & htl$HbA1c>6.5)), 1, 0)
head(htl)
```

Now let us assign "numeric" or "factor" status to the variables. For simplicity, we will treat a variable with less than 2 factor levels as "factor" data type, and else as "numeric" data type. DIC and Meth_Batch can also be considered as factors, however in this case we will need to do a multinomial (not a binomial / logistic) regression which is cumbersome, not clear how to extract adjusted R squared info, and most likely will not bring drammatically different results, so we will stick to only binomial / logistic regression for simplicity.

```{r}
for(i in 1:ncol(htl))
{
  if(length(levels(factor(htl[,i]))) > 2)
  {
    htl[,i]<-as.numeric(as.character(htl[,i]))
  }
  else
  {
    htl[,i]<-as.factor(htl[,i])
  }
}
```

Now we are going to select the 110 individuals with overlapping OMICs and keep only those individuals for further downstream analysis:

```{r}
htl<-htl[match(selected_ind,rownames(htl)),]
head(htl)
```

Now let us calculate pair-wise linear regression for the phenotypes and extract the adjusted R squared information which is equaivalent to the fraction of variation in the response variable explained by the predictor variable. In case the response variable is a factor, we will be using logistic regression (Generalized Linear Model, GLM, with family = "binomial") and calculate the adjusted R suared as:

$$R^2_{adj} = 1 - \frac{\rm{Residual Deviance}}{\rm{Null Deviance}}$$

```{r heatmap phenotypes,fig.width=10,fig.height=8}
htl_adj_r_squared<-matrix(NA,ncol=ncol(htl),nrow=ncol(htl))
for(i in 1:ncol(htl))
{
  print(i)
  for(j in 1:ncol(htl))
  {
    if(typeof(htl[,i])=="double" & (typeof(htl[,j])=="double" | typeof(htl[,j])=="integer"))
    {
      model<-suppressWarnings(lm(htl[,i]~htl[,j]))
      htl_adj_r_squared[j,i]<-suppressWarnings(summary(model)$adj.r.squared)
    }
    if(typeof(htl[,i])=="integer" & typeof(htl[,j])=="double")
    {
      model<-suppressWarnings(lm(htl[,j]~htl[,i]))
      htl_adj_r_squared[j,i]<-suppressWarnings(summary(model)$adj.r.squared)
    }
    if(typeof(htl[,i])=="integer" & typeof(htl[,j])=="integer")
    {
      model<-suppressWarnings(glm(htl[,i]~htl[,j],family="binomial"))
      htl_adj_r_squared[j,i]<-1-model$deviance/model$null.deviance
    }
  }
}
htl_adj_r_squared<-as.data.frame(htl_adj_r_squared)
colnames(htl_adj_r_squared)<-colnames(htl)
rownames(htl_adj_r_squared)<-colnames(htl)
htl_adj_r_squared[htl_adj_r_squared<0]<-0
htl_adj_r_squared
```

Now we can plot the heatmap of the adjusted R squared statistics and check how phenotypes and batches are related to each other:

```{r Phen Heatmap,fig.width=10,fig.height=8}
library("pheatmap")
pheatmap(htl_adj_r_squared, display_numbers=TRUE, fontsize=12, main="Human Pancreatic Islets Phenotypes: Adjusted R^2 of Association")
```

We can see that HbA1c and T2D are very strongly connected, they should since the T2D diagnostics relies on blood glucose level measurements. They also weakly cluster together with BMI implying relation between those three phenotypes, which also makes a lot of sense. Despite Age and Gender are believed to be a risk factor for T2D, we do not observe a reliable association between those three phenotypes in our sample. Meth_Batch and RNA_Batch are moderately connected but happily do not seem to influence any of the important phenotypes, perhaps only the Stimulatory Index (SI). There is one more strange / unexpected observations following from the heatmap: DIC seem to be strangly but weakly correlated with the T2D status.

### Preparing Phenotypes for T2D Prediction

Now let us select phenotypes that can be utilized in practice for predicting T2D. Obviously, Purity and DIC are technical variables that are good to have for the exploratory data analysis that we have done, but they are not to be used in the real world for predicting T2D despite DIC is moderately correlated with T2D due to technical reasons. For the same reason we exclude Meth_Batch, RNA_Batch and Random variables. HbA1c should be excluded because the T2D status is largely based on HbA1c values, so T2D and HbA1c are basically the same variable, so HbA1c should not be used for predicting T2D. Therefore we end up with just four variables: Age, Gender, SI and BMI. Let us merge them into an X matrix for future running PCA on it:

```{r}
library("mixOmics")
X<-subset(htl,select=c("Age","Gender","BMI","SI"))
X$Gender<-ifelse(as.character(X$Gender)=="Male",1,0)
X[1:10,1:4]
dim(X)
```

Next we will impute missing values with the median across the samples for each phenotype:

```{r}
for(i in 1:ncol(X))
{
  X[,i][is.na(X[,i])]<-median(X[,i],na.rm=TRUE)
}
```

In principal, we need to standardize each phenotype as the values from different phenotypes are on different scales. However, this usually brings negative values and hence technical complications and less transparency to the analysis. Another way to deal with this problem is to log-transform each phenotype which is equaivalent to a mild normalization / harmonization of the phenotypic values and bringing them to the same scale:

```{r}
X$Age<-log10(as.numeric(X$Age)+1)
X$BMI<-log10(as.numeric(X$BMI)+1)
X$SI<-log10(as.numeric(X$SI)+1)
X[1:10,1:4]
dim(X)
```

Now we are ready to do PCA on the phenotypic values:

```{r,fig.width=10,fig.height=8}
pca.phen<-pca(X, ncomp=4, center=TRUE, scale=TRUE)
pca.phen
plot(pca.phen,ylim=c(0,0.3))
```

The PCA shows that about 50% of the total variance is explained by the first 2 principal components. We will visualize PC1 vs. PC2 dependence coloring samples according to their diabetes status and gender:

```{r,fig.width=10,fig.height=8}
plotIndiv(pca.phen,group=as.factor(htl$T2D),ind.names=TRUE,ellipse=FALSE,legend=TRUE,title="PCA: Phenotypes from Human Islets")
plotIndiv(pca.phen,group=as.factor(htl$Gender),ind.names=TRUE,ellipse=FALSE,legend=TRUE,title="PCA: Phenotypes from Human Islets")
```

We see obvious clustering by Gender but not by T2D on genome-wide level. To understand which variables drive the PCA plot let us display the loadings for PC1 and PC2:

```{r,fig.width=10,fig.height=8}
plotLoadings(pca.phen,comp=1,method='median',contrib='max',ndisplay=20)
head(sort(abs(pca.phen$loadings$X[,"PC1"]),decreasing=TRUE),20)
plotLoadings(pca.phen,comp=2,method='median',contrib='max',ndisplay=20)
head(sort(abs(pca.phen$loadings$X[,"PC2"]),decreasing=TRUE),20)
```

We conclude that the main variation in the data comes from Gender and BMI variables.


### PLS-DA Analysis of Phenotypic Data

Now we will perform PLS-DA analysis, for this purpose we are going to construct the X and Y matrices in order to maximize their covariance, cov(X,Y), the X matrix has been already built in the previous section:

```{r}
gc()
library("mixOmics")
head(X)
Y<-as.factor(as.character(htl$T2D))
summary(Y)
```

We have approximately 29% of T2D individuals which is not crazy unbalanced, so there is a hope that the model does not learn only the majority class. Important to mention that a very naive / stupid classifier that predicts Non-T2D for any given individual should thus achieve 71% accuracy of classification. So our PLS-DA model should be better than the naive classifier and outperform the lower threshold of 71%.

```{r}
my_folds=2
my_nrepeat=10
my_progressBar=FALSE
my_cpus=1
```
```{r perf plsda,fig.width=10,fig.height=8}
gc()
phen_plsda.perf<-plsda(X, Y, ncomp=4)

ptm<-proc.time()
perf.plsda<-perf(phen_plsda.perf, validation='Mfold', folds=my_folds, progressBar=my_progressBar, nrepeat=my_nrepeat)
proc.time()-ptm

perf.plsda

head(perf.plsda$error.rate)

head(perf.plsda$error.rate.class)

plot(perf.plsda,overlay='dist',sd=TRUE)
```

We can see that BER Mahalanobis distance seems to reach their plateau or weak minimum at ncomp=2, so we will use 2 PLS components for further PLS-DA analysis.

```{r pls-da,fig.width=10,fig.height=8}
gc()
phen_plsda<-plsda(X, Y, ncomp=2)
phen_plsda$explained_variance
background = background.predict(phen_plsda, comp.predicted=2, dist = "mahalanobis.dist") 
plotIndiv(phen_plsda, comp=c(1,2), group=Y, ind.names=TRUE, ellipse=FALSE, background=background, legend=TRUE, title="Human Pancreatic Islets: PLS-DA of Phenotypic Data")
```

We do not see an obvious seperation between T2D and NonT2D individuals, meaning that the clinical phenotypes are not really good predictors of T2D. Plotting the loadings of the two PLS components we can see which phenotypes are responsible for the linear separation of the T2D and non-T2D individuals:

```{r pls comp,fig.width=10,fig.height=8}
plotLoadings(phen_plsda, comp=1, method='median', contrib='max', ndisplay=20)
head(sort(abs(phen_plsda$loadings$X[,"comp1"]),decreasing=TRUE),10)
plotLoadings(phen_plsda, comp=2, method='median', contrib='max', ndisplay=20)
head(sort(abs(phen_plsda$loadings$X[,"comp2"]),decreasing=TRUE),10)
```

We conclude that BMI and Age seem to be primarily responsible for T2D status prediction which makes a lot of sense.


### Predicting T2D Status from sPLS-DA Model

Finally we will randomly split the phenotypic data set into training (80% of samples) and validation (20% of samples) sets. This is needed to validate predictions of PLS-DA trained on the training data set. 

We are not going to perform again the tuning of the PLS-DA model on the training data set since from the previous analysis we know that first 2 PLS components minimize the mahalanobis.dist balanced error rate.  The accuracy of T2D vs NonT2D classification is very high, much higher than the 71% accuracy of the naive model. Now we will build confidence intervals by splitting the data set into train and test multiple times and running the PLS-DA classifier for every split.

```{r tune plsda train conf interval,fig.width=10,fig.height=8,eval = TRUE}
gc()
N_repeat<-100
comp1_acc<-vector()
comp2_acc<-vector()
for(k in 1:N_repeat)
{
  print(paste0("Working with split No.", k))
  gc()
  set.seed(k+100)
  test_samples<-rownames(X)[sample(1:length(rownames(X)),round(length(rownames(X))*0.2))]
  train_samples<-rownames(X)[!rownames(X)%in%test_samples]
  
  X.train<-X[match(train_samples,rownames(X)),]
  X.test<-X[match(test_samples,rownames(X)),]
  Y.train<-as.factor(as.character(htl[match(train_samples,rownames(htl)),]$T2D))
  Y.test<-as.factor(as.character(htl[match(test_samples,rownames(htl)),]$T2D))
  
  plsda.phen.train<-plsda(X.train, Y.train, ncomp=2)
  
  plsda.phen.predict<-predict(plsda.phen.train, X.test, dist='mahalanobis.dist')
  
  print(table(plsda.phen.predict$class$mahalanobis.dist[,1],Y.test))
  acc1<-round((sum(diag(table(plsda.phen.predict$class$mahalanobis.dist[,1],Y.test)))/sum(table(plsda.phen.predict$class$mahalanobis.dist[,1],Y.test)))*100)
  print(paste0("Classification Accuracy from PLS Component 1: ", acc1))
  print(table(plsda.phen.predict$class$mahalanobis.dist[,2],Y.test))
  acc2<-round((sum(diag(table(plsda.phen.predict$class$mahalanobis.dist[,2],Y.test)))/sum(table(plsda.phen.predict$class$mahalanobis.dist[,2],Y.test)))*100)
  print(paste0("Classification Accuracy from PLS Component 2: ", acc2))
  
  comp1_acc<-append(comp1_acc,acc1)
  comp2_acc<-append(comp2_acc,acc2)
  print("***********************************************************")
}

write.table(comp1_acc,file="Comp1_PLS_Phen_Acc.txt",col.names=FALSE,row.names=FALSE,quote=FALSE,sep="\t")
write.table(comp2_acc,file="Comp2_PLS_Phen_Acc.txt",col.names=FALSE,row.names=FALSE,quote=FALSE,sep="\t")
```

```{r,fig.width=10,fig.height=8}
gc()
comp1_acc_arch<-as.numeric(scan("Comp1_PLS_Phen_Acc.txt",what="character"))
comp2_acc_arch<-as.numeric(scan("Comp2_PLS_Phen_Acc.txt",what="character"))

#comp1_acc_arch<-c(comp1_acc,comp1_acc_arch)
#comp2_acc_arch<-c(comp2_acc,comp2_acc_arch)

hist(comp1_acc_arch,breaks=20,xlab="ACCURACY",main="Accuracy T2D Prediction from Phenotypes: PLS1",col="darkgreen")
abline(v=71,col="red",lwd=5)
mtext(paste0("Accuracy = ",mean(comp1_acc_arch)," +/- ",2*sd(comp1_acc_arch)))
hist(comp2_acc_arch,breaks=20,xlab="ACCURACY",main="Accuracy T2D Prediction from Phenotypes: PLS2",col="darkgreen")
abline(v=71,col="red",lwd=5)
mtext(paste0("Accuracy = ",mean(comp2_acc_arch)," +/- ",2*sd(comp2_acc_arch)))
```

We can compute how significantly different is the accuracy of the PLS-DA model compared to the naive 71% accuracy:

```{r}
gc()
sum(comp1_acc_arch<=71)/length(comp1_acc_arch)
sum(comp2_acc_arch<=71)/length(comp2_acc_arch)
rm(list=ls())
gc()
```

Finally here is the details on the system on which this document was compiled:
```{r}
sessionInfo()
```
